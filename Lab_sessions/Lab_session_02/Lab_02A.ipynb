{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEN122A Statistical Analysis of Choice Behaviour \n",
    "\n",
    "## `Lab session 02A:`\n",
    "## `The Mixed Logit model`\n",
    "\n",
    "**Delft University of Technology**<br>\n",
    "**Q2 2025**<br>\n",
    "**Instructor:** Sander van Cranenburgh<br>\n",
    "**TA:**  Gabriel Nova <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Instructions`\n",
    "\n",
    "**Lab sessions aim to:**<br>\n",
    "* Illustrate how models and theory discussed in the classroom work out in practice.\n",
    "* Help you gather hands-on modelling and data analysis skills.\n",
    "\n",
    "\n",
    "**Lab sessions are:**<br>\n",
    "* Learning environments where you work with Python and get support from TA and fellow students.\n",
    "* Not graded and do not have to be submitted.\n",
    "* A good preparation for the graded partial exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Use of AI tools`\n",
    "AI tools, such as ChatGPT and Co-pilot, are great tools to assist with programming. Moreover, in your later careers, you will work in a world where such tools are widely available. As such, we **encourage** you to use AI tools **effectively**. However, be careful not to overestimate the capacity of AI tools! AI tools cannot replace you: you still have to conceptualise the problem, dissect it and structure it to conduct proper analysis. We recommend being especially **reticent** with using AI tools for the more conceptual and reflection-oriented questions. <br>\n",
    "Futhermore **be aware** that during the `partial exam`, you will not have access to these tools (since internet access will be restricted)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Workspace set-up`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions in the [`README`](../../README.md) file to set up your programming environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Application: Estimating the Value of Travel Time`\n",
    "\n",
    "In this lab session, we will investigate the \"Value of Travel Time\" (VTT) distribution. The VTT of a traveller reflects the amount of money the traveller is **willing to pay** to reduce their travel time. The VTT is used to determine the benefits of new infrastructure projects. As travel time savings are the dominant and most salient benefits of new infrastructure, accurate inference of the distribution of the VTT is crucial for a rigorous underpinning of policy decisions. <br>\n",
    "\n",
    "During this lab, we will apply Mixed Logit choice models. We aim to uncover how tastes for travel time and travel cost are distributed in the population. Most of the analyses in this lab session are carried out in the so-called willingness-to-pay space. Willingness-to-pay space facilitates the inference of the VTT distribution.<br>\n",
    "\n",
    "For this study, we will use Stated Choice (SC) data (`Norway_VTT_2009.csv`) collected in 2009 to compute the Norwegian VTT. In this SC experiment, respondents faced nine choice tasks involving two alternatives and two attributes (travel cost and travel time). The data set consists of 5,832 participants, resulting in a total of 52,488 choice observations. The figure below shows one of the choice tasks (note that for the purposes of illustration we converted the currency unit (Kronor) into euros).\n",
    "\n",
    "![SC](assets/sc_experiment.png)\n",
    "\n",
    "**`Learning objectives lab session 02A`**\n",
    "\n",
    "After completing the following exercises, you will be able to:\n",
    "* Estimate Mixed Logit models that capture taste heterogeneity and panel effects\n",
    "* Interpret the modelling outcomes of Mixed Logit models\n",
    "* Specify utility models in Willingness-to-pay space\n",
    "\n",
    "\n",
    "\n",
    "**`This lab consists of 4 parts and has 2 exercises`**\n",
    "\n",
    "**Part 1**: Load and explore the data set\n",
    "\n",
    "**Part 2**: Linear-additive RUM-MNL model\n",
    "\n",
    "**Part 3**: Mixed Logit model for capturing taste heterogeneity \n",
    "- Exercise 1: \"Mixed Logit model with a normally distributed beta_tt\"\n",
    "\n",
    "**Part 4**: Willingness-to-Pay space \n",
    "- Exercise 2: \"Mixed Logit model with log-normally distributed VTT\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Import packages`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will import all the libraries that we will use in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biogeme\n",
    "import biogeme.database as db\n",
    "import biogeme.biogeme as bio\n",
    "import biogeme.biogeme_logging as blog\n",
    "from biogeme import models\n",
    "from biogeme.expressions import Beta, Variable, bioDraws, log, MonteCarlo, exp, exp\n",
    "\n",
    "\n",
    "# General packages\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm, lognorm\n",
    "\n",
    "# Pandas setting to show all columns when displaying a pandas dataframe\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the utils folder to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "\n",
    "# Import the bio_estimation_fcns from the utils folder\n",
    "from utils.bio_estimation_fcns import print_results, estimate_mnl, plot_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We invoke a so-called `logger` which enables us to see the progress during estimation.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the logger, if it has not been initialized yet\n",
    "try:\n",
    "    logger\n",
    "except NameError:    \n",
    "    logger = blog.get_screen_logger(level=blog.INFO)\n",
    "    print('Logger has been initialised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `1. Load and explore the data set` <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the data set\n",
    "data_path = Path('data/Norway_VTT_2009.csv')\n",
    "df = pd.read_table(data_path, sep=',')\n",
    "\n",
    "# Show descriptive statistics\n",
    "round(df.describe(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set contains the following variables:<br>\n",
    "\n",
    "| Variable       | Description                                                  | Type    |\n",
    "|---------------|-------------------------------------------------------------|---------|\n",
    "| `RespID`        | Unique identifier for each survey response             | Integer |\n",
    "| `CostL`         | Travel cost of left alternative [min]                  | Decimal |\n",
    "| `CostR`         | Travel cost of right alternative [min]                 | Decimal |\n",
    "| `TimeL`         | Travel time of left alternative [eur]                  | Decimal |\n",
    "| `TimeR`         | Travel time of right alternative [eur]                 | Decimal |\n",
    "| `Chosen`        | Indicates the alternative chosen       | Categorical |\n",
    "| `Mode`          | Type of Transport mode               | Categorical    |\n",
    "| `Gender`        | Gender of the respondent                                     | Categorical    |\n",
    "| `AgeClass`      | Classification of the respondent's age                       | Categorical    |\n",
    "| `IncClass`      | Classification of the respondent's income                    | Categorical    |\n",
    "| `Purpose`       | Purpose of the trip                                     | Integer    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we take the following data preprocessing steps:\n",
    "\n",
    "1. We keep only observations for the purpose 'long distance commute' and travel model 'car'.\n",
    "\n",
    "2. We convert the unit of cost from Norwegian Krone to euros to ease interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep only entries purpose == 5 (Long distance trips) & Mode == 1 (Car)\n",
    "df = df.loc[(df['Purpose'] == 5) & (df['Mode'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert the monetary unit to euros\n",
    "NOK2euro_exchange_rate = 9\n",
    "df[['CostL','CostR']] = df[['CostL','CostR']] .div(NOK2euro_exchange_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `2. Linear-additive RUM-MNL model`<br>\n",
    "We first estimate a linear-aditive RUM-MNL model. This model serves as our **benchmark** to compare against. But, before we can do this, we need to create the Biogeme database object and specify the optimiser and logger settings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Biogeme database`<br>\n",
    "To estimate a model in Biogeme, we must create the data set as a Biogeme database object and the attributes as Biogeme variable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Biogeme database object\n",
    "biodata = db.Database('Norway2009VTT', df)\n",
    "\n",
    "# Create Biogeme variable objects\n",
    "CostL  = Variable('CostL')\n",
    "CostR  = Variable('CostR')\n",
    "TimeL  = Variable('TimeL')\n",
    "TimeR  = Variable('TimeR')\n",
    "\n",
    "# The choice and availabilities of the alternatives\n",
    "Chosen = Variable('Chosen')\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create a linear-additive RUM-MNL model`<br>\n",
    "Now, we have the biogeme database object and set the environment, we can estimate our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Benchmark MNL VTT model'\n",
    "\n",
    "# Define model parameters\n",
    "B_tt = Beta('B_tt', -0.1, None, None, 0)\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0)\n",
    "\n",
    "# Definition of the utility functions\n",
    "VL = B_tt * TimeL + B_tc * CostL # (left alternative)\n",
    "VR = B_tt * TimeR + B_tc * CostR # (right alternative)\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: VL, 2: VR}     \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: 1, 2: 1} # (both alternatives are always available)\n",
    "\n",
    "# Estimate the model\n",
    "results_mnl = estimate_mnl(V,AV,Chosen,biodata,model_name)\n",
    "\n",
    "# Print the estimation statistics\n",
    "print_results(results_mnl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Compute the Value of Travel Time`<br><br>\n",
    "The linear-additive RUM-MNL model allows for easy computation of the (mean) VTT. <br>\n",
    "\n",
    "$VTT = {\\frac{dV}{dtt}}/{\\frac{dV}{dtc}}$<br><br>\n",
    "$VTT = \\frac{\\beta_{tt}}{\\beta_{tc}}$\n",
    "\n",
    "To take the ratio, we access the estimated betas in the `beta_hat` dataframe that was created in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time and print the mean VTT\n",
    "# We multiply by 60 to convert the value of travel time from minutes to hours\n",
    "beta_hat_mnl = results_mnl.get_beta_values()\n",
    "VTT_mnl = 60 * (beta_hat_mnl['B_tt'] / beta_hat_mnl['B_tc'])\n",
    "print(f'Value of travel time MNL model:  ‚Ç¨{VTT_mnl:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `3. Mixed Logit model for capturing taste heterogeneity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.1 Theory`<br>\n",
    "In the MNL model, we postulate that tastes (e.g., ùõΩ_tc) are equal across people in the population. As such, the taste parameter of an MNL model represents the mean taste in the population. The Mixed Logit (ML) model resolves this limitation. It explicitly models taste heterogeneity by means of random variables.\n",
    "\n",
    "Mathematically, the unconditional choice probability is given by:\n",
    "\n",
    "$P_{ni} = \\int_{\\beta_n}    [P_{ni}|\\beta_n] \\cdot f(\\beta_n|\\sigma)d\\beta_n$\n",
    "\n",
    "As can be seen, the MXL choice probability does not have a closed-form expression. Therefore, it needs to be approximated using simulation.<br>\n",
    "To do that, we simulate the choice probabilities using a large number of draws `(R)` from the density function $f(Œ≤_n|\\sigma)$. <br>\n",
    "That is, we compute the conditional choice probability (which is a simple MNL) for each draw of $\\beta_n^{r}$ with $r=1,..,R$, and then take the average across the draws to compute the unconditional choice probability.\n",
    "\n",
    "<span style=\"text-decoration: overline;\">P</span>$_{ni} = \\frac{1}{R} \\sum_{r=1}^R P_{ni}(Œ≤_n^r)$\n",
    "\n",
    "Finally, we use the unconditional choice probabilities to compute the Log-Likelihood of the data given the model:\n",
    "\n",
    "$LL(X,|\\beta,\\sigma)= \\sum_{n=1}^N \\sum_{j=1}^J y_{nj} \\cdot ln($<span style=\"text-decoration: overline;\">P</span>$_{nj})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.2 MXL with normally distributed taste parameters`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To estimate an MXL, model with normally distributed taste parameters, we must specify the random parameters (for all randomly distributed betas that we wish to estimate). To do this in Biogeme, we use the following code to construct the random parameter:<br>\n",
    "\n",
    "                B_xx_rnd = B_xx + sigma_xx * bioDraws('B_xx_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "We use this to do construct random taste parameters for both $\\beta_{tt}$ and $\\beta_{tc}$<br>\n",
    "Note that apart from that we make the marginal utilities for travel time and travel cost random (as opposed to fixed), the utility function is the same as under our linear-additive RUM-MNL benchmark model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model specification` <br>\n",
    "\n",
    "Now, we will define the (random) parameters, the utility functions, and their availabilities. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'ML with normal distributed B_tt and B_tc'\n",
    "\n",
    "# Define the model parameters\n",
    "B_tt = Beta('B_tt', -0.1, None, None, 0)\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0)    \n",
    "sigma_tt = Beta('sigma_tt', 1, None, None, 0)\n",
    "sigma_tc = Beta('sigma_tc', 1, None, None, 0)\n",
    "\n",
    "# Construct the random taste parameter for beta_tt and beta_tc\n",
    "B_tt_rnd = B_tt + sigma_tt * bioDraws('B_tt_rnd', 'NORMAL_HALTON2')\n",
    "B_tc_rnd = B_tc + sigma_tc * bioDraws('B_tc_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions \n",
    "VL = B_tt_rnd * TimeL + B_tc_rnd * CostL\n",
    "VR = B_tt_rnd * TimeR + B_tc_rnd * CostR   \n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: VL, 2: VR}\n",
    "            \n",
    " # Create a dictionary to describe the availability conditions of each alternative\n",
    "AV = {1: 1, 2: 1} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Estimation function for MXL` <br>\n",
    "\n",
    "Now that we have specified the MXL model, we need to estimate it. To do so, we create the following function `estimate_mxl` which we can re-use.\n",
    "\n",
    "The estimation function takes the following inputs:\n",
    "* Dictionary with the utilities functions for each alternative (**V**)\n",
    "* Dictionary with the availabilities for each alternative (**AV**)\n",
    "* Chosen alternatives array (**CHOICE**)\n",
    "* Biogeme database which contains the relevant attributes and characteristics (**database**)\n",
    "* Model name (**\"string\"**)\n",
    "* Number of draws for the simulation (**num_draws**) (default = 100)\n",
    "\n",
    "The function uses Monte Carlo simulation to **simulate the log-likelihood function** for estimating the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function estimates the MXL model and returns the estimation results\n",
    "def estimate_mxl(V,AV,CHOICE,biodata,model_name, num_draws = 100):\n",
    "    \n",
    "    # The conditional probability of the chosen alternative is a logit\n",
    "    condProb = models.logit(V, AV ,CHOICE)\n",
    "\n",
    "    # The unconditional probability is obtained by simulation\n",
    "    uncondProb = MonteCarlo(condProb)\n",
    "\n",
    "    # The Log-likelihood is the log of the unconditional probability\n",
    "    LL = log(uncondProb)\n",
    "\n",
    "    # Create the Biogeme estimation object containing the data and the model\n",
    "    biogeme = bio.BIOGEME(biodata , LL, number_of_draws=num_draws)\n",
    "\n",
    "    # Set reporting levels\n",
    "    biogeme.generate_pickle = False\n",
    "    biogeme.generate_html = False\n",
    "    biogeme.save_iterations = False\n",
    "    biogeme.modelName = model_name\n",
    "\n",
    "    # Estimate the parameters and print the results\n",
    "    results = biogeme.estimate()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's estimate the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the model and print the results\n",
    "num_draws = 100\n",
    "results_mxl_normal = estimate_mxl(V,AV,Chosen,biodata,model_name,num_draws)\n",
    "\n",
    "# Print the results\n",
    "print_results(results_mxl_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualisation of the estimated random parameters`<br>\n",
    "Visualisation of the estimated random parameters helps to get a feeling for their shape. To visualise the distributions we use a dedicated function from `utils.bio_estimation_fcns`. This function takes as input a dictionary that specifies the distribution type for each random parameter you want to plot, as well as the range we want to plot over. Note that we names of the random parameters should match for this to work. <br>\n",
    "For instance, to plot the distribution of \"tt\" the names of the parameters associated with tt should end with \"_tt\" (thus, be named \"beta_tt\" and \"sigma_tt\" or \"b_tt\" and \"sig_tt\").<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of the random parameters using a dedicated function from utils.bio_estimation_fcns\n",
    "# Create the dictionary with the distribution types\n",
    "distr_types = {\n",
    "    'tc':  {'dist': 'normal'},\n",
    "    'tt':  {'dist': 'normal'},\n",
    "}\n",
    "# Plot the distributions of the random parameters, by passing it the biogeme results, the dictionary with the distribution types, and the x-axis limits\n",
    "plot_distributions(results_mxl_normal, distr_types, xmin = -3, xmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `3.3 Reflection`<br>\n",
    "We can make the following observations from the results of the MXL model:\n",
    "1. The model fits the data better than the linear-additive RUM-MNL model. So this model is preferred over the linear-additive RUM-MNL model.\n",
    "2. The estimated standard deviations of the random parameters are significant, indicating that there is substantial taste heterogeneity in the population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However**, the MXL model with two normally distributed random parameters does not provide a way to compute the VTT. When we would compute the VTT by taking the ratio of $\\beta_{time}$ over $\\beta_{cost}$ we end up dividing by **zero** because the **normal distribution** has mass at zero, see the left-hand side plot. In other words, the model predicts some people don't care about cost. This implies that when we compute the VTT, we divide by zero. In other words, the model implies that some people have a $\\beta_{tc} of 0$ and, by extension, an infinite VTT. As a result, the **mean** VTT would be infinite as well. As such, a normally distributed $\\beta_{tc}$ is generally **not a good idea** if one wants to compute the mean VTT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 1: Mixed Logit model with a normally distributed beta_tt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` Modify the code to estimate the MXL model above, such that only $\\beta_{tt}$ is treated as a normally distributed random variable.\n",
    "\n",
    "`B` Compute the **mean** VTT for this model. Since the normal distribution is symmetric, its mean is simply given by the mean of the random parameter.<br>\n",
    "So, the mean VTT is given by  VTT_MXL = $60\\cdot \\frac{\\beta_{tt}}{\\beta_{tc}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `4. Willingness-to-Pay space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.1. Theory`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results under 3.2 (and intuition) tell us that people are differently sensitive to cost. But, as discussed under 3.3, we cannot specify $\\beta_{tc}$ as a randomly distributed parameter (or, to be more precise, not as one that uses a distribution which has support over the full domain [-‚àû,‚àû], like a normal distribution). To circumvent this problem, we can cleverly re-parameterise our model. This **reparametrisation** involves a transformation from **`utility space`** to **`Willingness-to-Pay (WTP) space`**. This transformation allows us to estimate the VTT (distribution) directly, and simplifies the modelling. It works as follows:<br><br>\n",
    "\n",
    "\n",
    "The utility specification in `utility space` is:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot TC_1 + \\beta_{tt} \\cdot TT_1$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot TC_2 + \\beta_{tt} \\cdot TT_2$<br><br>\n",
    "\n",
    "We factorise $\\beta_{tc}$ in both utility functions. This gives us:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot (TC_1 + (\\frac{\\beta_{tt}}{\\beta_{tc}}) \\cdot TT_1)$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot (TC_2 + (\\frac{\\beta_{tt}}{\\beta_{tc}}) \\cdot TT_2)$<br><br>\n",
    "\n",
    "Noting that $VTT = \\frac{\\beta_{tt}}{\\beta_{tc}}$, we obtain:\n",
    "\n",
    "$V_1 = \\beta_{tc} \\cdot (TC_1 + VTT \\cdot TT_1)$<br>\n",
    "$V_2 = \\beta_{tc} \\cdot (TC_2 + VTT \\cdot TT_2)$<br><br>\n",
    "\n",
    "Hence, with this model, we can **directly** estimate the VTT (and $\\beta_{tc}$). Therefore, this model is in the `Willingness-to-Pay space`.<br> \n",
    "\n",
    "**Starting values for estimating the VTT in the WTP space**<br>\n",
    "Whenever we estimate a discrete choice model, we need to provide starting values for the optimisation algorithm. For conventional linear-additive RUM-MNL models, the starting values are (largely) inconsequential because of its concave log-likelihood function (see [tutorial 3](https://github.com/SEN1221TUD/Tutorials/blob/main/tutorial3/tutorial3_concave_likelihood_MNL.ipynb)). However, for models estimated in WTP space and more complex models in general, the starting values can have impact. When estimating the VTT in the WTP space, it is good practice to provide **reasonable starting values** (thus starting values which imply a nonzero, positive VTT).\n",
    "<br>\n",
    "<br>\n",
    "`MNL model in WTP space`<br>\n",
    "Let's first see how this works out for a simple MNL model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'Benchmark MNL in WTP space'\n",
    "\n",
    "# Define model parameters\n",
    "vtt  = Beta('vtt', 10/60, None, None, 0) # Note that we use VTT of 10 euros/hr as the starting value. /60 converts minutes to hours\n",
    "B_tc = Beta('B_tc', -0.1, None, None, 0) # Note that we use a reasonable starting value for B_tc (same as in the MNL model)\n",
    "\n",
    "# Definition of the utility functions\n",
    "VL = B_tc * (CostL + vtt * TimeL)\n",
    "VR = B_tc * (CostR + vtt * TimeR)\n",
    "\n",
    "# Associate utility functions with alternatives\n",
    "V = {1: VL, 2: VR}     \n",
    "\n",
    "# Associate the availability conditions with the alternatives\n",
    "AV = {1: 1, 2: 1} \n",
    "\n",
    "# Estimate the model\n",
    "results_wtp_mnl = estimate_mnl(V,AV,Chosen,biodata,model_name)\n",
    "\n",
    "# Print the estimation statistics\n",
    "print_results(results_wtp_mnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "beta_hat_wtp_mnl = results_wtp_mnl.get_beta_values()\n",
    "VTT_wtp_mnl = 60 * beta_hat_wtp_mnl['vtt']\n",
    "print(f'Value of travel time MNL model in WTP space:  ‚Ç¨{VTT_wtp_mnl:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.2 Reflection`<br>\n",
    "Comparing these results with the benchmark MNL VTT model, we make two observations:\n",
    "* We obtain `EXACTLY` the same VTT\n",
    "* We obtain `EXACTLY` the same model fit \n",
    "* **We immediately obtain the VTT and the associated standard error!** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.3. MXL in Willingness-to-Pay space`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MXL with normally distributed taste parameters`<br>\n",
    "Now, let's see how WTP space enables us to directly estimate the VTT distribution in the context of the Mixed Logit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name\n",
    "model_name = 'ML WTP space with normally distributed vtt'\n",
    "\n",
    "# Parameters definition enabling the construction of random parameters\n",
    "mu_vtt = Beta('mu_vtt',     10/60, None, None, 0) # Note that we use VTT of 10 euros/hr as the starting value. /60 converts minutes to hours\n",
    "B_tc   = Beta('B_tc',        -0.1, None, None, 0) # Note that we use a reasonable starting value for B_tc (same as in the MNL model)\n",
    "sigma_vtt = Beta('sigma_vtt', 0.1, None, None, 0) # Note that we use a nonzero starting value for sigma_vtt\n",
    "\n",
    "# Construction of random parameters\n",
    "vtt_rnd = mu_vtt + sigma_vtt * bioDraws('vtt_rnd', 'NORMAL_HALTON2')\n",
    "\n",
    "# Definition of the utility functions \n",
    "VL = B_tc * (CostL + vtt_rnd * TimeL)\n",
    "VR = B_tc * (CostR + vtt_rnd * TimeR)   \n",
    "\n",
    "# Create a dictionary to list the utility functions with the numbering of alternatives\n",
    "V = {1: VL, 2: VR}\n",
    "\n",
    "# Create a dictionary to describe the availability conditions of each alternative\n",
    "AV = {1: 1, 2: 1} \n",
    "\n",
    "# Estimate the model\n",
    "num_draws = 100\n",
    "results_wtp_mxl_normal = estimate_mxl(V, AV, Chosen, biodata, model_name, num_draws)\n",
    "\n",
    "# Print the results in a table\n",
    "print_results(results_wtp_mxl_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the value of travel time\n",
    "beta_hat_wtp_mxl_normal = results_wtp_mxl_normal.get_beta_values()\n",
    "VTT_wtp_mxl_normal = 60*beta_hat_wtp_mxl_normal['mu_vtt']\n",
    "print(f'Value of travel time MXL model in WTP space:  ‚Ç¨{VTT_wtp_mxl_normal:.2f} per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualisation of the estimated VTT distribution`<br>\n",
    "To visualise the VTT distributions we use the dedicated function from `utils.bio_estimation_fcns`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of the VTT distribution\n",
    "# Create the dictionary with the distribution types\n",
    "distr_types = {\n",
    "    'vtt':  {'dist': 'normal'},\n",
    "}\n",
    "# Plot the distributions of the random parameters, by passing it the biogeme results, the dictionary with the distribution types, and the x-axis limits\n",
    "# Note that the unit of the VTT distribution is euros per minute\n",
    "plot_distributions(results_wtp_mxl_normal, distr_types, xmin = -1, xmax = 120/60, xlabel='VTT (euros per minute)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `4.4 Reflection`<br>\n",
    "* Using a Mixed Logit model in the Willingness-to-Pay space, we are able to estimate the distribution of the VTT **directly**. Hence, this model allows jointly for unobserved heterogeneity in cost and time without running into problems caused by dividing by zero.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Exercise 2: Mixed Logit with log-normally distributed VTT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`A` In the above plot showing the distribution of the VTT, we see that a substantial part of the VTT distribution lies in the negative domain. Explain why this is behaviourally counterintuitive and undisirable when we want to model the choice behaviour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to impose positive all VTTs are positive is by using a log-normal distribution. In contrast to the normal distribution, the log-normal distribution is defined over the positive domain only. Next, **you** will test if the assumption that the VTT distribution in the population is **`log-normally distributed`** explains the data **better** than the assumption that the VTT distribution in the population is normally distributed.<br>\n",
    "\n",
    "To do that, you must create a random vtt parameter with a log-normal VTT distribution. Draws from the log-normal distribution are very simple to obtain from draws from the normal distribution. We only have to exponentiate draws from the normal distribution:<br>\n",
    "\n",
    "            vtt_rnd = exp(mu_vtt + sigma_vtt  * bioDraws('vtt_rnd', 'NORMAL_HALTON2'))\n",
    "            \n",
    "\n",
    "Estimate this model and interpret its results.<br>\n",
    "\n",
    "\n",
    "`B` Compare the log-likelihood of the MXL model with normally distributed VTT and with log-normally distributed VTT. Which model fits the data better?<br>\n",
    "\n",
    "`C` What can you infer from the `vtt` and `sigma` parameters about the distribution of the VTT?<br>\n",
    "\n",
    "`D` Compute the mean of the estimated log-normal distribution, i.e. `mean_lognormal` (based on your estimated `mu` and `sigma`). <br>\n",
    "\n",
    "To do so, take a look at [https://en.wikipedia.org/wiki/Log-normal_distribution](https://en.wikipedia.org/wiki/Log-normal_distribution) to see how this is done. Look for the formula for the mean in the right-hand side panel on the web page.\n",
    "\n",
    "`E` Plot the shape of the log-normal distribution for the estimated `mu` and `sigma`. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END üéâ<br>\n",
    "### Now, you can continue with Lab 02B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEN122A_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
